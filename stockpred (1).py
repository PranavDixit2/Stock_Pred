# -*- coding: utf-8 -*-
"""stockpred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aGVe_ymZiElIln9cl3c6jWNQG_N0Jskq
"""

pip install yfinance joblib plotly tensorflow scikit-learn streamlit

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import joblib
import os
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- Feature calculation functions ---

def calculate_ema(data, span):
    return data['Close'].ewm(span=span, adjust=False).mean()

def calculate_rsi(data, window=14):
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / (loss + 1e-8)
    rsi = 100 - (100 / (1 + rs))
    return rsi

def calculate_bollinger_bands(data, window=20):
    sma = data['Close'].rolling(window=window).mean()
    std_dev = data['Close'].rolling(window=window).std()
    data['BB_upper'] = sma + (2 * std_dev)
    data['BB_lower'] = sma - (2 * std_dev)
    return data

def calculate_macd(data, short_window=12, long_window=26, signal_window=9):
    short_ema = data['Close'].ewm(span=short_window, adjust=False).mean()
    long_ema = data['Close'].ewm(span=long_window, adjust=False).mean()
    data['MACD'] = short_ema - long_ema
    data['MACD_signal'] = data['MACD'].ewm(span=signal_window, adjust=False).mean()
    return data

def calculate_features(data):
    data['EMA_9'] = calculate_ema(data, 9)
    data['EMA_21'] = calculate_ema(data, 21)
    data['EMA_50'] = calculate_ema(data, 50)
    data['EMA_200'] = calculate_ema(data, 200)
    data['RSI_14'] = calculate_rsi(data)
    data = calculate_bollinger_bands(data)
    data = calculate_macd(data)
    data['Volume_Change'] = data['Volume'].pct_change()
    data['Price_Change'] = data['Close'].pct_change()

    lag_features = [
        'Close', 'Volume', 'EMA_9', 'EMA_21', 'EMA_50', 'EMA_200',
        'RSI_14', 'BB_upper', 'BB_lower', 'MACD', 'MACD_signal',
        'Volume_Change', 'Price_Change'
    ]
    for feature in lag_features:
        for lag in range(1, 6):
            data[f'Lag_{feature}_{lag}'] = data[feature].shift(lag)

    data.dropna(inplace=True)
    return data

def preprocess_data(data):
    target = data['Close'].shift(-1)
    data = data.dropna()
    target = target.loc[data.index]

    base_features = [
        'Open', 'High', 'Low', 'Close', 'Volume', 'EMA_9', 'EMA_21', 'EMA_50', 'EMA_200',
        'RSI_14', 'BB_upper', 'BB_lower', 'MACD', 'MACD_signal', 'Volume_Change', 'Price_Change'
    ]

    lagged_feature_bases = [
        'Close', 'Volume', 'EMA_9', 'EMA_21', 'EMA_50', 'EMA_200',
        'RSI_14', 'BB_upper', 'BB_lower', 'MACD', 'MACD_signal',
        'Volume_Change', 'Price_Change'
    ]

    features = base_features.copy()
    for feature_base in lagged_feature_bases:
        for lag in range(1, 6):
            features.append(f'Lag_{feature_base}_{lag}')

    return target, features

def prepare_data(data, features, target, window_size=10):
    feature_scaler = MinMaxScaler()
    target_scaler = MinMaxScaler()

    scaled_features = feature_scaler.fit_transform(data[features])
    X = np.array([scaled_features[i-window_size:i] for i in range(window_size, len(scaled_features))])
    y_raw = target.values[window_size:]
    y = target_scaler.fit_transform(y_raw.reshape(-1, 1)).flatten()

    return X, y, feature_scaler, target_scaler

def calculate_prediction_intervals(model, X_test, y_test, target_scaler):
    y_pred_scaled = model.predict(X_test, verbose=0).flatten()
    y_test_actual = target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
    y_pred_actual = target_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
    residuals = y_test_actual - y_pred_actual
    std_dev = np.std(residuals)
    z_score = 1.96
    margin_of_error = z_score * std_dev
    lower_bound = y_pred_actual - margin_of_error
    upper_bound = y_pred_actual + margin_of_error
    return y_pred_actual, lower_bound, upper_bound, y_test_actual

def display_evaluation_metrics(y_test_actual, y_pred):
    mae = mean_absolute_error(y_test_actual, y_pred)
    mse = mean_squared_error(y_test_actual, y_pred)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((y_test_actual - y_pred) / (y_test_actual + 1e-8))) * 100
    st.write("### Evaluation Metrics (on Test Set)")
    st.write(f"- Mean Absolute Error (MAE): ${mae:.2f}")
    st.write(f"- Root Mean Squared Error (RMSE): ${rmse:.2f}")
    st.write(f"- Mean Absolute Percentage Error (MAPE): {mape:.2f}%")

def plot_predictions(data, y_test_actual, y_pred, lower_bound, upper_bound):
    test_dates = data.index[-len(y_test_actual):]
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=test_dates, y=y_test_actual, mode='lines', name='Actual Prices', line=dict(color='blue', width=2)))
    fig.add_trace(go.Scatter(x=test_dates, y=y_pred, mode='lines', name='Predicted Prices', line=dict(color='red', width=2, dash='dot')))
    fig.add_trace(go.Scatter(x=test_dates, y=upper_bound, mode='lines', name='Upper Bound (95% CI)', line=dict(color='rgba(128, 128, 128, 0.5)', width=0), showlegend=False))
    fig.add_trace(go.Scatter(x=test_dates, y=lower_bound, mode='lines', name='95% Confidence Interval', line=dict(color='rgba(128, 128, 128, 0.5)', width=0), fill='tonexty', fillcolor='rgba(192, 192, 192, 0.3)'))
    fig.update_layout(title='B-LSTM T+1 Forecast Performance', xaxis_title='Date', yaxis_title='Price (USD)', template='plotly_white')
    st.plotly_chart(fig, use_container_width=True)

def predict_next_day(model, data_processed, features, feature_scaler, target_scaler, window_size=10):
    last_data = data_processed[features].values[-window_size:]
    last_data_scaled = feature_scaler.transform(last_data)
    last_data_reshaped = last_data_scaled.reshape((1, window_size, len(features)))
    predicted_price_scaled = model.predict(last_data_reshaped, verbose=0)
    predicted_price = target_scaler.inverse_transform(predicted_price_scaled).flatten()
    return predicted_price[0]

# --- Streamlit UI ---

st.title("Stock Price Prediction with Bidirectional LSTM")
st.write("Predict next-day closing price with confidence intervals and evaluation metrics.")

TICKER = st.text_input("Enter Stock Ticker (e.g. AAPL)", value="AAPL").upper()
WINDOW_SIZE = 10
TRAIN_EPOCHS = 50

if st.button("Run Prediction"):

    with st.spinner("Fetching data..."):
        data_raw = yf.download(TICKER, period="5y", progress=False)
        if data_raw.empty:
            st.error("No data found for ticker. Please check the symbol.")
            st.stop()

    with st.spinner("Calculating features..."):
        data_features = calculate_features(data_raw.copy())
        if len(data_features) < 50:
            st.error(f"Not enough data after feature engineering ({len(data_features)} samples).")
            st.stop()

    with st.spinner("Preprocessing data..."):
        target, features = preprocess_data(data_features.copy())
        data_for_lstm = data_features.loc[target.index].assign(Target=target)
        X, y, feature_scaler, target_scaler = prepare_data(data_for_lstm, features, data_for_lstm['Target'], WINDOW_SIZE)

    if len(X) < 30:
        st.error(f"Insufficient samples ({len(X)}) after cleaning and windowing. Need at least 30.")
        st.stop()

    test_size = max(int(len(X) * 0.2), 10)
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]

    model_path = f"lstm_model_{TICKER}.keras"
    scaler_path = f"scalers_{TICKER}.joblib"

    if os.path.exists(model_path) and os.path.exists(scaler_path):
        model = load_model(model_path)
        feature_scaler, target_scaler = joblib.load(scaler_path)
        st.success("Loaded existing model and scalers.")
    else:
        st.info("Training new model...")
        from tensorflow.keras.regularizers import l2
        from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
        from tensorflow.keras.models import Sequential
        import tensorflow as tf

        input_shape = (X_train.shape[1], X_train.shape[2])
        model = Sequential()
        model.add(Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001)), input_shape=input_shape))
        model.add(Dropout(0.2))
        model.add(Bidirectional(LSTM(32, kernel_regularizer=l2(0.001))))
        model.add(Dropout(0.2))
        model.add(Dense(1))
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])

        callbacks_list = [
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)
        ]

        history = model.fit(
            X_train, y_train,
            epochs=TRAIN_EPOCHS,
            batch_size=64,
            validation_data=(X_test, y_test),
            callbacks=callbacks_list,
            verbose=0
        )
        model.save(model_path)
        joblib.dump((feature_scaler, target_scaler), scaler_path)
        st.success("Training complete and model saved.")

    y_pred, lower_bound, upper_bound, y_test_actual = calculate_prediction_intervals(model, X_test, y_test, target_scaler)
    predicted_price = predict_next_day(model, data_features, features, feature_scaler, target_scaler, WINDOW_SIZE)

    st.write(f"### Predicted next-day closing price for {TICKER}: ${predicted_price:.2f}")

    display_evaluation_metrics(y_test_actual, y_pred)
    plot_predictions(data_for_lstm, y_test_actual, y_pred, lower_bound, upper_bound)
